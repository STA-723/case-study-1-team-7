---
title: "Summary of What I've Done"
author: "Youngsoo Baek"
date: "\\today"
output: pdf_document
---

This analysis excludes observations for which there are missing values for any of the variables excluding the response (`gestational_age`) and `albumin`. The observations for which we have missing values for any of the possible model predictors are 525, about `r 525/2380`\% of the data. Response observed at greater than 46 weeks are replaced with the upper bound of 46 weeks, as we suspect many of the extremely long gestational ages recorded are measurement errors, and 46 weeks are considered the upper bound for normal deliveries.

```{r}
Longnecker <- readRDS("./Longnecker.rds")
Longnecker <- Longnecker[,colnames(Longnecker)!="albumin"] # Throw away albumin
Longnecker$center <- as.factor(Longnecker$center) # Factorize center
Longnecker[Longnecker$gestational_age > 46, "gestational_age"] <- 46 # Truncate at age == 46
# Complete case analysis for missing variables

x <- model.matrix(gestational_age ~ . - center, data = Longnecker)
miss_indices <- as.integer(row.names(x))
Longnecker_complete <- Longnecker[miss_indices,] # Only those non-missing obs.
```

## 1. Linear Regression Model
Suppose the relationship between gestational age and the chemical compounds can be modeled as linear, on some suitable scale (which may well be not the case). Main challenges include...

  * What models to be considered
  
  * Multicollinearity and confounding problem
  
  * Modeling heterogeneity between centers

### i. What models to consider
The question of interest is the association between gestational week and chemicals including DDE's and `r sum(grepl("pcb", colnames(Longnecker)))` different PCB's. In a hypothetical experiment study, we would investigate the causal effect of these chemicals on the gestational age through random assignment of the mothers subject to the study into the exposure vs. control groups. Since this is impossible, we want to study the association between the response and different chemical variables, while adjusting for as many demographic variables observed as possible.

We may consider the following "naive" regression model for predicting gestational age as the null model. This model smooths over the observed gestational age while adjusting for any observed demographic variables, and triglyceride/cholesterol levels of each individual:
$$
\begin{aligned}
\text{gestational age}\sim 1+ \text{triglycerides} + \text{cholesterol}+ \text{race} + \text{maternal age} + \text{smoking status} + \text{score variables} + \text{center}.
\end{aligned}
$$
The score variables correspond to the level of education, income, and occupation under some suitable score transform. For categorical variables `race` and `center`, white race and center ID 5 are baseline categories, respectively. One possible issue with this null model can arise when these predictors in themselves are highly correlated; the highest Spearman correlation is between the two fat carrier variables, about `r round(with(Longnecker_complete, cor(triglycerides, cholesterol, method = "spearman")) * 100, 1)`\%.

This "naive" model can be fit straightforwardly; we may notice that triglycerides level and race are statistically significant variables. The signs for point estimates of fat carrier variables are negative, as expected. The large variance for cholesterol level coefficient estimate can be due to multicollinearity issues, as those for the three score variables. 
```{r}
base_model <- lm(gestational_age ~ triglycerides + cholesterol + race + maternal_age + 
                   smoking_status + score_education + score_income + score_occupation + center, 
                 data = Longnecker_complete)
summary(base_model)
```

As we will see, this null model is hardly "improved" by other models from an adjusted/unadjusted $R^2$ standpoint.

Alternatively, we may simply develop a model that estimates the effect of chemical compounds simply on whether a mother delivers a baby prematurely, based on the 37-week criterion. A logistic model can be thus similarly constructed and later fit. We suffer a substantial amount of loss in the possible information we can gather from this model, however, as we already know that deliveries right at the threshold do not have significant impact on the infants' health.

### ii. Multicollinearity
Let's say we perform an $F$-test comparing the null model explained above, against one alternative model at a time, that includes one of the DDE/PCB levels variables as an additional predictor. For example:
$$
\begin{aligned}
\text{Null model:}\quad\text{gestational age} \sim 1 + \text{...} \\
\text{Alternative:}\quad\text{gestational age} \sim 1 + DDE + \text{...}
\end{aligned}
$$
which test is carried out below, and indeed based on the test $p$-value, we find DDE is an interesting enough variable to explain more variability among different mothers' gestational age:

```{r}
anova(update(base_model, . ~ . + dde))
```

Of course we can play this game long enough, with all possible combinations of DDE and PCB variables, and come across a multiple comparison problem - most of the supposedly small enough $p$-values will be probable due to mere chance. Furthermore, the main issue with different PCB compound levels is that they are often heavily (positively) correlated. Hence, the "full" regression model estimates often have hugely inflated variance, and the inference for each PCB variable's separated effect on premature deliveries may well be infeasible.

We may want to sum up all PCB levels and use this as a new proxy variable for some "total" PCB effect. This may or may not have a valid scientific meaning. Instead, we may want to use a proxy variable that is a linear combination of PCB levels, with different weights. The first principal component is a good candidate. This, again, may or may not have a valid scientific meaning, but at least has a good mathematical property, based on the PCA theory.
```{r}
PC1_pcb <- prcomp(x[,grepl("pcb", colnames(x))])$x[,1]
Longnecker_complete_pc <- cbind.data.frame(Longnecker_complete[,!grepl("pcb", colnames(Longnecker_complete))],
                                           PC1 = PC1_pcb)
```

Hence we can fit both ordinary and logistic regression models as follows. This model retains the multicollinearity problem between DDE and PCB levels, as seen if we apply a nested-model $F$-test. There can be a confounder problem that may need to be accounted for in the form of a prior: e.g., DDE and different PCB chemicals can share a common underlying chemical structure, etc.

```{r}
# 1. Regression
lm_with_pc <- lm(gestational_age ~ ., data = Longnecker_complete_pc)

# F-test: If one (dde) is included, the other may not be significant
anova(update(lm_with_pc, . ~ . -dde + dde))
anova(update(lm_with_pc, . ~ . -dde - PC1 + dde + PC1))

# 2. Logistic regression 
Longnecker_complete_pc$early <- (Longnecker_complete_pc$gestational_age < 37)
llm_with_pc <- glm(early ~ . - gestational_age, family = binomial, data = Longnecker_complete_pc)
```

We may summarise in a table the coefficients corresponding to `dde`, the DDE level, and `PC1`, the "total" PCB effect proxy, along with intercepts corresponding to each individual center:
```{r, echo=F, include=T}
lm_coefs <- c( coef(lm_with_pc)[c("dde", "PC1")],
   "center5" = as.numeric(coef(lm_with_pc)[1]),
   coef(lm_with_pc)[1] + coef(lm_with_pc)[ grepl("center", names(coef(lm_with_pc))) ] )
lm_confint <- rbind(confint(lm_with_pc)[c("dde", "PC1"),],
                    "center5" = confint(lm_with_pc)[1,],
                    confint(lm_with_pc)[1,] + 
                      confint(lm_with_pc)[grepl("center", rownames(confint(lm_with_pc))),] )
lm_coefs <- cbind.data.frame(Mean = lm_coefs, lm_confint)

llm_coefs <- c( coef(llm_with_pc)[c("dde", "PC1")],
   "center5" = as.numeric(coef(llm_with_pc)[1]),
   coef(llm_with_pc)[1] + coef(llm_with_pc)[ grepl("center", names(coef(llm_with_pc))) ] )
llm_confint <- rbind(confint(llm_with_pc)[c("dde", "PC1"),],
                    "center5" = confint(llm_with_pc)[1,],
                    confint(llm_with_pc)[1,] + 
                      confint(llm_with_pc)[grepl("center", rownames(confint(llm_with_pc))),] )
llm_coefs <- cbind.data.frame(Mean = llm_coefs, llm_confint)

knitr::kable(lm_coefs, format = "latex", caption = "Estimates for Normal regression", digits = 3)
knitr::kable(llm_coefs, format = "latex", caption = "Estimates for Logistic regression", digits = 3)
```

For DDE, the above table tells us that an additional 1ug exposure to this chemical leads to a $|-0.006 \times 7| \approx .04$-day earlier delivery, adjusted for other variables; for a mother in the dataset with median DDE exposure level, this indicates barely a day earlier delivery compared to no exposure and in otherwise identical conditions.

The logistic model, on the other hand, tells us that an additional 1ug exposure to DDE leads to about $0.009$-increase in the log odds of the probability of delivering a baby prematurely. By the properties of the logistic curve, we may think of this coefficient divided by 4 as the upper bound for an increase in probability of premature delivery for 1ug additional exposure (adjusted for other predictors). For DDE levels, that additional increase in probability is no more than `r round(25*llm_coefs["dde","Mean"], 1)`\%.

### iii. Heterogeneity between centers
Models above fit a fixed effects model for `center` variable, so that each center has a mean shift in the gestational age, and each of these intercepts is estimated from the sample in that center only. This does not induce any pooling between the different mean gestional ages across centers; alternatively, random effects model, or equivalently a Bayesian hierarchical regression, induces pooling.

```{r}
# 3. Linear mixed effects model
library(lme4)
lmm_with_pc <- lmer(gestational_age ~ . - early - center + (1|center), data = Longnecker_complete_pc)
lmm_with_pc
```

(Response to Yunran's concerns also: I think I can more clearly articulate the reservations I have about this model. The mixed effects regression model fit here is obviously equivalent to a hierarchical regression with unregularized priors; however, it is a very *restrictive* subclass, meaning that if these centers have very high level of inhomogeneity, this model fit could be much more inadequate than the fixed effects model. B/c estimation-wise, I don't think there is a center with *that* small a sample size--the concern should be more modeling-wise, meaning whether it is reasonable to assume that all centers have a common unknown mean and homogenous variance. If your concern about certain labs being very inhomogenous is valid, that assumption breaks down. Of course, you can fit a Bayeseian hierarchical model suggested by Merlise or something, and incorporate additional center-specific parameters, etc., so that they do not have common variance. That, however, involves more model building, and in any case the commont frequentist MME method is much less extensible in that case.)
