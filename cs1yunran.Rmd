---
title: "cs1yunran"
author: "YunranChen"
date: "1/14/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(corrplot)
library(naniar)
library(ggplot2)
library(dplyr)
library(tibble)
library(tidyr)
library(purrr)
library(lme4)
```

```{r load data}
data=readRDS("Longnecker.rds")
data=data%>%select(gestational_age,dde:cholesterol,center)
data #reorder the column, put the gestational_age as the first cols
summary(data)
```

## missing data analysis

- over 90% missing `albumin`, around 20% missing `score_*`; others less than 0.1%
- around 474 out of 2380 missing `score_*` together. (usually `score_*` miss together)
- Each center have missing values but distinct proportion of missing values.



- drop the albumin (check whether bias exist?)
- impute or drop the score_* ? can explore the relation of the complete data to see whether a significant relation? Then decide?
- drop the pcb_* NA (imputation; outlier; if do pcb selection we do not even need it)

```{r}
vis_miss(data)
gg_miss_upset(data)
gg_miss_var(data,facet = center)
```

## correlation between variables

Goal: evaluate the correlation between dde, pcbs and y (gestational_age)
Y: discrete I(<37) (preferred but info loss) or continuous ?
X: 
- all covariates have weak correlation to Y
- strong correlation between pcbs ->summary?
- center: as a group -- hierachical model?
- cholesteroal and triglycerides need to be controlled; have positive correlation to pcb/dde
- race matters; have interaction with pcbs
- scores matters: have interaction with pcbs + dde + age; but 20% missing
- the missing of albumin may due to some reason: the data w/o missing show stronger correlation to Y

Hierarchical Regression? Testing pcbs as a group variates or pick some important pcbs(118, 138, 153) -- variable selection or combine them? 
How to deal with missing values?

[Removing the `score_*` and `albumin` + complete cases] 
- super weak relation to covariates: almost negative(make sense); to dde (-0.09), triglycerides (-0.08), race (-0.06)
- strong positive correlation among covariates especially from pcb_074 to pcb_203; positive correlation between dde and pcb_; cholesterol and triglycerides have positive correlation to dde and pcb_(make sense); negative relation between race and pcb_028-118 then flip to positive relation (interesting.-interaction?);
- heterogeneity across distinct centers: (meaningless but ...) positive correlation to dde(0.17), race(0.38); negative correlation to ppb_074(-0.28), ppb_105(-0.16), ppb_118(-0.2), triglycerides(-0.18), maternal_age(0.18), 

[Remove `albumin` + complete cases]
- scores_ negative related to dde (-0.15), race (-0.27 to -0.39) , but positive to y(0.08), pcb028-118(0.1+); positive correlation among scores_ (0.42-0.53);

[complete cases]
- `albumin` positive correlation to dde and pcb
- relative stronger relation compared to the previous one; stronger negative correlation for pcb_153-race; pcb_074-118,income & occupation do not effect.
- relative stronger relation between scores to pcb153-203 compared to previous 

```{r eda}
data_=data%>%mutate(race=as.numeric(race))

M=cor(as.matrix(na.omit(data_[,c(1:13,15:16,20:23)])))
corrplot.mixed(M,number.cex=.6, upper="ellipse")

M1=cor(as.matrix(na.omit(data_[,c(1:13,15:23)])))
corrplot.mixed(M1,number.cex=.6, upper="ellipse")


M2=cor(as.matrix(na.omit(data_)))
corrplot.mixed(M2,number.cex=.5, upper="ellipse")

na.omit(data)
data=as.tibble(data)

```


```{r}
ggplot(data_,mapping = aes(x=gestational_age))+geom_histogram()+theme_bw()+geom_vline(xintercept =37)
ggplot(data,mapping = aes(x=as.factor(center),y=gestational_age,color=race))+geom_boxplot()+theme_bw()
datapcb=data_%>%select(pcb_028:pcb_203,race,center)%>%gather(data=.,key = pcb,value = dose,-race,-center)%>%mutate(center=factor(center),race=factor(race))
datapcb
ggplot(datapcb,aes(x=pcb,y=dose,color=race))+geom_boxplot()+theme_bw()+facet_wrap(.~center)
#if not wrapped by center, before 118, black less than white then flip. But consider the center, black always greater than white.
```

## linear mixed effect model


```{r}
data_46=data%>%mutate(y=gestational_age)
data_46[data_46$y>46,"y"]=46
data_46=data_46%>%select(-gestational_age,-albumin)%>%mutate(race=factor(race),center=factor(center))
ggplot(data_46,aes(x=pcb_203))+geom_histogram()+facet_wrap(.~race)+theme_bw()

data_46 %>%
  keep(is.numeric) %>% 
  gather() %>% 
  ggplot(aes(value)) +
    facet_wrap(~ key, scales = "free") +
    geom_histogram()
```


No interaction; No scores; group effect


```{r}
data_46_noscore=data_46%>%select(-score_education,-score_income,-score_occupation)%>%na.omit()
model1=lmer(y~1+.-center+(1|center),data=data_46_noscore)
model1
fix=summary(model1)%>%coef()
CI= confint(model1)
cbind(fix,CI[-c(1:2),])
# not significant except dde,triglycerides; heterogeneity across race exist;
model1_nore=lm(y~1+.-center,data=data_46_noscore)
X.stat = 2*c(logLik(model1_nore)-logLik(model1))
p = 0.5*(1-pchisq(X.stat,1)+1-pchisq(X.stat,0))
p # heterogeneity across center
plot(model1,resid(.,scaled=TRUE)~fitted(.),abline=0,xlab="Fitted Values",ylab="Standardized Residuals")
qqnorm(resid(model1))
qqline(resid(model1))
BIC(model1)
model1_nopcb=lmer(y~1+dde+triglycerides+race+maternal_age+smoking_status+cholesterol+(1|center),data=data_46_noscore)
BIC(model1_nopcb)
anova(model1,model1_nopcb) #pcbs not significant; but BIC improves a lot if include them
data_46
model1_nodde=lmer(y~1+.-center-dde+(1|center),data=data_46_noscore)
BIC(model1_nodde)
anova(model1,model1_nodde) # dde is significant

```

No interaction; consider scores

```{r}
data_46_wscore=data_46%>%na.omit()
model2=lmer(y~1+.-center+(1|center),data=data_46_wscore)
fix=summary(model2)%>%coef()
CI= confint(model2)
cbind(fix,CI[-c(1:2),])
# not significant; heterogeneity across race exist; (the difference may due the high correlated X's, unrobust!)
model2_nore=lm(y~1+.-center,data=data_46_wscore)
X.stat = 2*c(logLik(model2_nore)-logLik(model2))
p = 0.5*(1-pchisq(X.stat,1)+1-pchisq(X.stat,0))
p # heterogeneity across center
plot(model2,resid(.,scaled=TRUE)~fitted(.),abline=0,xlab="Fitted Values",ylab="Standardized Residuals")
qqnorm(resid(model2))
qqline(resid(model2))
BIC(model2)
model2_nopcb=lmer(y~1+dde+triglycerides+race+maternal_age+smoking_status+cholesterol+score_education+score_income+score_occupation+(1|center),data=data_46_wscore)
BIC(model2_nopcb)
anova(model2,model2_nopcb) #pcbs not significant; but BIC increase if include them
model2_nodde=lmer(y~1+.-center-dde+(1|center),data=data_46_wscore)
BIC(model2_nodde)
anova(model2,model2_nodde) # dde is not significant; BIC suggest exclude it

```


take away: have to do variable selection! or else the result is not robust.

PCA visulization

```{r}
data_wscore.pca <- prcomp(data_46_wscore[,-22]%>%mutate(race=as.numeric(race),center=as.numeric(center)), center = TRUE,scale. = TRUE)
ggbiplot(data_wscore.pca,labels="")

data_noscore.pca <- prcomp(data_46_noscore[,-19]%>%mutate(race=as.numeric(race),center=as.numeric(center)), center = TRUE,scale. = TRUE)
ggbiplot(data_noscore.pca,labels="")

data_noscore.pca_ <- prcomp(data_46_noscore[,1:12], center = TRUE,scale. = TRUE)
ggbiplot(data_noscore.pca_,labels="")

```


```{r}
data_46_noscore%>%group_by(center)%>%summarise(mean=mean(y),count=n(y))%>%ggplot(aes(x=count,y=mean))+geom_point()
data%>%filter(gestational_age>42)%>%nrow()
```


## try frequentists' lasso

```{r}
#install.packages("glmnet")
library("glmnet")
train.data=data_46_wscore
x <- model.matrix(y~., train.data)[,-1]
# Convert the outcome (class) to a numerical variable
y <- train.data$y

cv.lasso <- cv.glmnet(x, y, alpha = 1)
plot(cv.lasso)
# Fit the final model on the training data
model <- glmnet(x, y, alpha = 1,
                lambda = cv.lasso$lambda.min)
# Display regression coefficients
coef(model)
#coef(cv.lasso, cv.lasso$lambda.1se)
#coef(cv.lasso, cv.lasso$lambda.min)
```

```{r}
train.data=data_46_wscore
x <- model.matrix(y~., train.data)[,-1]
# Convert the outcome (class) to a numerical variable
y <- ifelse(train.data$y<37,1,0)

cv.lasso <- cv.glmnet(x, y, alpha = 1)
plot(cv.lasso)
# Fit the final model on the training data
model <- glmnet(x, y, alpha = 1,
                lambda = cv.lasso$lambda.min)
# Display regression coefficients
coef(model) 

#coef(cv.lasso, cv.lasso$lambda.1se)
coef(cv.lasso, cv.lasso$lambda.min)
```

